{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Generators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> * 제너레이터는 한 번에 하나씩 구성요소를 반환해주는 이터러블을 생성해주는 객체이다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> * 제너레이터의 주요 목적은 메모리를 절약하는 것이다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 중첩 루프 효율적으로 벗어나기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_nested_bad(array, desired_value):\n",
    "    coords = None\n",
    "    for i, row in enumerate(array):\n",
    "        for j, cell in enumerate(row):\n",
    "            if cell == desired_value:\n",
    "                coords = (i, j)\n",
    "                break\n",
    "        if coords is not None:\n",
    "            break\n",
    "    \n",
    "    if coords is None:\n",
    "        raise ValueError('{} not found'.format(desired_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _iterate_array2d(array2d):\n",
    "    for i, row in enumerate(array2d):\n",
    "        for j, cell in enumerate(row):\n",
    "            yield (i, j), cell\n",
    "\n",
    "def search_nested(array, desired_value):\n",
    "    try:\n",
    "        coord = next(coord for (coord, cell) in _iterate_array2d(array) if cell == desired_value)\n",
    "    except StopIteration:\n",
    "        raise ValueError('{} not found'.format(desired_value))\n",
    "        \n",
    "    return coord\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 코루틴(Coroutine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "쓰레드(Threads): OS 혹은 런타임 환경이 쓰레드들간 switching을 주관함 (스케쥴러)  \n",
    "코루틴(Coroutine): 프로그래머가 스스로 셋 포인트를 정해 언제 switching 될 지를 결정함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing coroutine\n",
      "Searching prefix: Dear\n",
      "Dear Atul\n",
      "Closing coroutine\n"
     ]
    }
   ],
   "source": [
    "def print_name(prefix):\n",
    "    print('Searching prefix: {}'.format(prefix))\n",
    "    try:\n",
    "        while True:\n",
    "            name = (yield)\n",
    "            if prefix in name:\n",
    "                print(name)\n",
    "    except GeneratorExit:\n",
    "        print('Closing coroutine')\n",
    "        \n",
    "            \n",
    "corou = print_name('Dear')\n",
    "corou.__next__() # This will start execution of coroutine\n",
    "\n",
    "corou.send('Deer Atul')\n",
    "corou.send('Dear Atul')\n",
    "corou.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 코루틴을 이용한 파이프라인 형성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with printing!\n",
      "I'm sink, i'll print tokens\n",
      "Searching for ing\n",
      "running\n",
      "moving\n",
      "Done with filtering!!\n"
     ]
    }
   ],
   "source": [
    "def producer(sentence, next_coroutine): \n",
    "    ''' \n",
    "    Producer which just split strings and \n",
    "    feed it to pattern_filter coroutine \n",
    "    '''\n",
    "    tokens = sentence.split(\" \") \n",
    "    for token in tokens: \n",
    "        next_coroutine.send(token) \n",
    "    next_coroutine.close() \n",
    "  \n",
    "def pattern_filter(pattern=\"ing\", next_coroutine=None): \n",
    "    ''' \n",
    "    Search for pattern in received token  \n",
    "    and if pattern got matched, send it to \n",
    "    print_token() coroutine for printing \n",
    "    '''\n",
    "    print(\"Searching for {}\".format(pattern)) \n",
    "    try: \n",
    "        while True: \n",
    "            token = (yield) \n",
    "            if pattern in token: \n",
    "                next_coroutine.send(token) \n",
    "    except GeneratorExit: \n",
    "        print(\"Done with filtering!!\") \n",
    "  \n",
    "def print_token(): \n",
    "    ''' \n",
    "    Act as a sink, simply print the \n",
    "    received tokens \n",
    "    '''\n",
    "    print(\"I'm sink, i'll print tokens\") \n",
    "    try: \n",
    "        while True: \n",
    "            token = (yield) \n",
    "            print(token) \n",
    "    except GeneratorExit: \n",
    "        print(\"Done with printing!\") \n",
    "  \n",
    "pt = print_token() \n",
    "pt.__next__() \n",
    "pf = pattern_filter(next_coroutine = pt) \n",
    "pf.__next__() \n",
    "  \n",
    "sentence = \"Bob is running behind a fast moving car\"\n",
    "producer(sentence, pf) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Clean Code in Python - Chapter 7: Using Generators\n",
    "\n",
    "> Methods of the Generators Interface.\n",
    "\n",
    "\"\"\"\n",
    "import time\n",
    "\n",
    "from log import logger\n",
    "\n",
    "\n",
    "class DBHandler:\n",
    "    \"\"\"Simulate reading from the database by pages.\"\"\"\n",
    "\n",
    "    def __init__(self, db):\n",
    "        self.db = db\n",
    "        self.is_closed = False\n",
    "\n",
    "    def read_n_records(self, limit):\n",
    "        return [(i, f\"row {i}\") for i in range(limit)]\n",
    "\n",
    "    def close(self):\n",
    "        logger.debug(\"closing connection to database %r\", self.db)\n",
    "        self.is_closed = True\n",
    "\n",
    "\n",
    "def stream_db_records(db_handler):\n",
    "    \"\"\"Example of .close()\n",
    "\n",
    "    >>> streamer = stream_db_records(DBHandler(\"testdb\"))  # doctest: +ELLIPSIS\n",
    "    >>> len(next(streamer))\n",
    "    10\n",
    "\n",
    "    >>> len(next(streamer))\n",
    "    10\n",
    "    \"\"\"\n",
    "    try:\n",
    "        while True:\n",
    "            yield db_handler.read_n_records(10)\n",
    "            time.sleep(.1)\n",
    "    except GeneratorExit:\n",
    "        db_handler.close()\n",
    "\n",
    "\n",
    "class CustomException(Exception):\n",
    "    \"\"\"An exception of the domain model.\"\"\"\n",
    "\n",
    "\n",
    "def stream_data(db_handler):\n",
    "    \"\"\"Test the ``.throw()`` method.\n",
    "\n",
    "    >>> streamer = stream_data(DBHandler(\"testdb\"))\n",
    "    >>> len(next(streamer))\n",
    "    10\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        try:\n",
    "            yield db_handler.read_n_records(10)\n",
    "        except CustomException as e:\n",
    "            logger.info(\"controlled error %r, continuing\", e)\n",
    "        except Exception as e:\n",
    "            logger.info(\"unhandled error %r, stopping\", e)\n",
    "            db_handler.close()\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
